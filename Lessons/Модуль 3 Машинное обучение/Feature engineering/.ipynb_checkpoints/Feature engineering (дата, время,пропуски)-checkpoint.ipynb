{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, возвращаемся к нашему другу Коле и его данным по букмекерской конторе.  \n",
    "\n",
    "Коля хочет расширять бизнес и увеличивать прибыль, и мы поможем ему \n",
    "с помощью аналитических навыков и знания нужных инструментов. \n",
    "Работать будем с теми же данными - log.csv и users.csv.\n",
    "\n",
    "Что мы уже сделали?\n",
    "\n",
    "Загрузили данные (и побороли ошибки, связанные с плохим форматом данных).\n",
    "Дали признакам (колонкам) соответствующие имена.\n",
    "Научились фильтровать данные и применять к ним apply.\n",
    "Обнаружили часть ошибок в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие вопросы остались?\n",
    "Вспомним часть вопросов из прошедшего модуля.\n",
    "\n",
    "Сколько раз человеку надо прийти, чтобы сделать ставку?\n",
    "\n",
    "Каков средний выигрыш в процентах?\n",
    "\n",
    "Каков баланс по каждому пользователю?\n",
    "\n",
    "Какие города самые выгодные?\n",
    "\n",
    "В каких городах самая высокая ставка?\n",
    "\n",
    "Сколько в среднем времени проходит от первого посещения сайта до первой попытки?\n",
    "\n",
    "Мы постараемся ответить не только на эти, но и на многие другие вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие бывают пропуски\n",
    "Вот список значений, которые по умолчанию считаются как пропуски: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan', 'null'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls')\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pandas есть метод isna(), который возвращает таблицу такой же размерности, что и на вход, но значения в ней - True или False. True, если данное значение является пропуском, и False в ином случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.head(5).isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log.columns = ['user','time','bet','win']\n",
    "log.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте количество пропусков в столбце time. Метод isna() есть не только у DataFrame, но и у Series. Это значит, что применять его можно не только ко всей таблице, но и к каждому столбцу отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['time'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление пропусков\n",
    "Пропуски можно удалять автоматически. Во многих случаях это правильно, так как данные с большим количеством пропусков часто не имеют смысла и не приносят никакой пользы.  \n",
    "\n",
    "Удалять данные с пропусками можно с помощью метода dropna().\n",
    "\n",
    "Параметр axis в методе dropna() говорит методу, по какой оси удалять значения.  \n",
    "\n",
    "1. Если нужно удалить строки, в которых встречается пропуск (NaN), следует указать axis=0.  Зачем это делать? Например, у нас из 1000 примеров данных про пользователей пропуски есть в пяти. Разумно их удалить, так как их количество пренебрежимо мало.\n",
    "\n",
    "2. Если нужно удалить столбцы, в которых встречается пропуск (NaN), нужно указывать axis=1. Зачем? Иногда в одном конкретном столбце пропусков настолько много, что с ними просто не хочется возиться - смысла в них все равно почти нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один интересный параметр - subset. Что он делает? Если передать в него список значений по одной оси (например, названия столбцов) и задать при этом в параметре axis другую ось (в нашем случае 0), то мы удалим те строки, для которых в данных столбцах находится пропуск. То же самое работает и наоборот: нужно поменять axis на 1 и вместо названий столбцов передавать индексы строк.\n",
    "\n",
    "log = log.dropna(subset=['time'],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log.head(5)\n",
    "log.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['user'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['time'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del log['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубли  - это повторяющиеся строки в данных. В сложных случаях строки могут быть практически одинаковые, но не совсем.\n",
    "\n",
    "Самая частая причина очень банальна: дубли появляются из-за человеческих ошибок или невнимательности.\n",
    "\n",
    "Например, при добавлении записи в систему вы случайно два раза нажали на кнопку \"добавить\". Если система позволяет иметь одинаковые записи, поздравляю - у вас в данных появились дубли.\n",
    "\n",
    "Еще одна причина - слияние баз данных. Например, вы переносите телефоны из контактной книжки (физической, в которую заносили номера ручкой на бумагу, такие были популярны в прошлом) в телефон. Назвали в одном месте Сашу Сашей, а в другом Александром. Да, это тоже дубль, просто сам случай немного более сложный.\n",
    "\n",
    "Сложным случаям типа последнего можно посвятить очень много времени, так что это материал для другого, более продвинутого курса по анализу данных. Скажу лишь, что в каждом конкретном случае подозрительные случаи нужно рассматривать отдельно, это требует кропотливой работы. \n",
    "\n",
    "Мы же рассмотрим простой случай, когда у вас в данных есть идентичные строки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как удалить простые дубли\n",
    "В pandas есть метод для удаления дублей (дубликатов) - drop_duplicates(). Он просто удаляет повторяющиеся строки:\n",
    "\n",
    "01. import pandas as pd  \n",
    "02. df = pd.read_csv('data.csv')\n",
    "03. df.drop_duplicates()  \n",
    "У данного метода тоже есть параметр subset, в этом случае нужно передавать список содержащий названия столбцов.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls')\n",
    "log.columns = ['user','time', 'bet', 'win']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ut = log[['user','time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ut.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_time = log['time'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.time = log.time.apply(lambda x:str(x).replace('[','') if ('[' in str(x)) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = log.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечение временных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for i in log.time:\n",
    "    i = str(i)\n",
    "    time_list.append(datetime.strptime(i, '%Y-%m-%d %H:%M:%S'))\n",
    "max(time_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(log.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv(\"log.xls\")  \n",
    "log = log.dropna()  \n",
    "log.columns = ['user_id', 'time', 'bet', 'win']  \n",
    "log['time'] = log['time'].apply(lambda x: x[1:])  \n",
    "log['time'] = pd.to_datetime(log['time'])  \n",
    "# log['time'] = log.time.apply(lambda x: x.minute)\n",
    "log['time'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека pandas позволяет использовать аксессор dt для упрощения подобной работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['year'] = log['time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из часто используемых методов в pandas является value_counts().\n",
    "\n",
    "Этот метод возвращает Series, который содержит количества уникальных элементов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.Series([1, 1, 1, 2, 3, 4, 4])  \n",
    "test.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте оригинальные данные log.csv, столбец time.\n",
    "\n",
    "Подсказка: можно использовать value_counts().\n",
    "\n",
    "Найдите минуту, которая встречалась в данных чаще всего. Введите ответ в поле ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['minute'] = log['time'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log['minute'].value_counts(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите месяц, который встречался в данных реже всего.\n",
    "\n",
    "* надо подготовить  столбец Time. Пропуски надо удалять именно в нём, потомц что применение общего dropna() удалит лишние строки (пропуски не только в стобце времни потому что)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls')\n",
    "log.columns = ['user','time', 'bet', 'win']\n",
    "log_time = pd.DataFrame(log['time'])\n",
    "log_time = log_time.dropna(axis = 0)\n",
    "\n",
    "log_time['time'] = log_time['time'].apply(lambda x:str(x).replace('[','') if ('[' in str(x)) else x)\n",
    "log_time['time'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_time['time'] =pd.to_datetime(log_time['time'])\n",
    "log_time['month'] = log_time['time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_time['month'].value_counts(ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте, сколько дней в данных являются выходными (то есть субботой или воскресеньем). Введите ответ в поле ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls')\n",
    "log.columns = ['user','time','bet','win']\n",
    "log_time = pd.DataFrame(log['time'])\n",
    "log_time = log_time.dropna()\n",
    "\n",
    "log_time['time']=log_time.time.apply(lambda x: str(x).replace('[','') if ('[' in str(x)) else x)\n",
    "log_time['time'] = pd.to_datetime(log_time['time'])\n",
    "\n",
    "log_time['day'] = log_time['time'].dt.dayofweek\n",
    "\n",
    "count = 0\n",
    "for i in log_time['day']:\n",
    "    if i == 5 or i == 6:\n",
    "        count +=1\n",
    "    else:\n",
    "        pass\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Договоримся, что с 0 до 5 часов - ночь, с 6 до 11 - утро, с 12 до 17 - день, с 18 до 23 - вечер.\n",
    "\n",
    "Важно: для выполнения задания вам нужно будет избавиться от пропусков только в столбце time. Вспомните, как избавиться от пропусков только по конкретному признаку.\n",
    "\n",
    "Посчитайте, какое время дня встречается в данных реже всего. Введите ответ в поле ниже: ночь, утро, день или вечер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls')\n",
    "log.columns = ['user','time','bet','win']\n",
    "log_time = pd.DataFrame(log['time'])\n",
    "log_time = log_time.dropna()\n",
    "\n",
    "log_time['time']=log_time.time.apply(lambda x: str(x).replace('[','') if ('[' in str(x)) else x)\n",
    "log_time['time'] = pd.to_datetime(log_time['time'])\n",
    "\n",
    "log_time['daytime'] = log_time['time'].dt.hour\n",
    "\n",
    "night = 0\n",
    "day = 0\n",
    "morning = 0\n",
    "evening = 0\n",
    "for i in log_time['daytime']:\n",
    "    if 0<=i<=5:\n",
    "        night +=1\n",
    "    elif 6<=i<=11:\n",
    "        morning +=1\n",
    "    elif 12<=i<=17:\n",
    "        day +=1\n",
    "    elif 18<=i<= 23:\n",
    "        evening +=1\n",
    "print('ночь{} ,утро{} ,день{} ,вечер{}'.format(night,morning,day,evening))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте повторим то, что мы прошли в этой секции. Напишите код, который создаст признак hour из признака time в датасете log.csv. Для этого:\n",
    "\n",
    "1. загрузите датасет log.csv в переменную log, дальше работать будем с ней;\n",
    "\n",
    "2. установите имена столбцов: ['user_id', 'time', 'bet', 'win'];\n",
    "\n",
    "3. избавьтесь от пропусков в log;\n",
    "\n",
    "4. приведите переменную time к подходящему для извлечения признаков виду;\n",
    "\n",
    "5. получите значение часа для каждой строки в переменной time и запишите в столбец hour в log.\n",
    "\n",
    "Результатом будет таблица log со столбцом hour внутри."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls', header = None)\n",
    "log.columns = ['user','time','bet','win']\n",
    "log = log.dropna(subset=['time'],axis = 0)\n",
    "log['time']=log.time.apply(lambda x: str(x).replace('[','') if ('[' in str(x)) else x)\n",
    "log.time = pd.to_datetime(log.time)\n",
    "log['hour'] = log.time.dt.hour\n",
    "\n",
    "log\n",
    "\n",
    "# log_time['time'] = pd.to_datetime(log_time['time'])\n",
    "\n",
    "# log_time['daytime'] = log_time['time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls', header = None) #применяем header = None, потому что без этого воспримет первую строку\n",
    "# как заголовок\n",
    "\n",
    "log.columns = ['user','time','bet','win']\n",
    "log = log.dropna()\n",
    "log['time']=log.time.apply(lambda x: str(x).replace('[','') if ('[' in str(x)) else x)\n",
    "log.time = pd.to_datetime(log.time)\n",
    "log['hour'] = log.time.dt.hour\n",
    "\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё про пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле, удаление пропусков - довольно грубое решение, потому что мы можем случайно выбросить что-то полезное. Например, у вас есть данные о людях: пол, возраст, цвет глаз, город. При этом для большинства людей не записан цвет глаз. Удалять строки с пропусками может быть неудачным решением -  у нас почти не останется данных. Удалить столбец с цветом глаз - решение получше. Возможно, есть решение еще лучше - например, заполнить все пропуски цветом глаз \"карие\". Ответ на вопрос \"Правильно ли будет так сделать?\" можно получить после уточнения информации: в каких-то странах преобладает один цвет глаз, в каких-то - другой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый норм - это заполнение пропусков константой, чтоб не терять данные удаляя строки или стобцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls', header = None) \n",
    "\n",
    "log.columns = ['user','time','bet','win']\n",
    "log['bet'] = log['bet'].fillna(0)\n",
    "log['win'] = log['win'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае со столбцом bet предполагаем, что там где пропуски - значит люди приходили, но не делали ставок. Можем заменить на 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте, сколько раз люди приходили, но не делали ставок. Для этого заполните пропуски в столбце bet значением 0 и посчитайте количество таких значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log['bet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поработаем с признаком win, в котором тоже есть пропуски.\n",
    "\n",
    "Иногда нужно заполнять пропуски не одним и тем же числом, а разными, в зависимости от какого-то условия. Перед нами именно этот случай.\n",
    "\n",
    "Предположим, что если в признаке win находится пропуск, то выигрыша не было. Здесь два возможных случая:\n",
    "\n",
    "1. Человек не делал ставки и ничего не выиграл. То есть просто пришел, посмотрел и ушел.\n",
    "2. Человек делал ставку, но не выиграл. Значит, выигрыш на самом деле является отрицательным значением - это проигрыш."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем метод, который заполнит пропуски в признаке win в соответствии с предположением выше. \n",
    "\n",
    "Для этого можно применить метод apply() ко всей таблице и передать ему функцию, которая вычисляет размер выигрыша (или проигрыша) по следующей схеме:\n",
    "\n",
    "1. Если значение в столбце win существует (не пропуск) - вернуть это же значение. Это значит, что человек выиграл.\n",
    "2. Если вместо значения в столбце win пропуск, вернуть 0.\n",
    "На выходе получится столбец без пропусков. Следующим шагом будет замена старого столбца win на новый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls', header = None) \n",
    "\n",
    "log.columns = ['user','time','bet','win']\n",
    "log['bet'] = log['bet'].fillna(0)\n",
    "log['win'] = log['win'].fillna(0)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_win(row):  \n",
    "    if row['win'] == row['bet']:\n",
    "        row['win'] = 0\n",
    "#         print(row['win']) \n",
    "        return row['win']\n",
    "    elif row['bet'] > row['win']:\n",
    "        row['win'] = -1\n",
    "#         print(row['win']) \n",
    "        return row['win']\n",
    "    else:\n",
    "        row['win'] = row['win']\n",
    "#         print(row['win']) \n",
    "        return row['win']\n",
    "        \n",
    "  \n",
    "# Применяем функцию  \n",
    "new_win = log.apply(lambda row: fillna_win(row), axis=1)  \n",
    "\n",
    "\n",
    "# Заменяем старый столбец с пропусками на новый без пропусков  \n",
    "log['win'] = new_win  \n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сколько раз проиграли?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log['win'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sence(row):\n",
    "    net = row['win']-row['bet']\n",
    "    print(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['net'] = log.apply(lambda row: sence(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = log[log['net'] > 0]\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(positive['net']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.median(positive['net']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = positive[positive['net']<7500]\n",
    "boxplot = sort.boxplot(column = ['net'])\n",
    "positive['net'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте, какой процент посещений букмекерской конторы оборачивался ставкой. Для этого поделите количество ставок (значений больше 0) на общее количество посещений конторы. Результат округлите до одного знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet = log[log['bet']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet['bet'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round((bet['bet'].count()/log['bet'].count())*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['net'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(bet['bet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(bet['net']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = bet[bet['net']<0]\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(negative['net']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = bet[bet['net']>0]\n",
    "lose = bet[bet['net']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(win['bet'].count()/bet['bet'].count())\n",
    "print(lose['bet'].count()/bet['bet'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. загрузите датасет log.csv;\n",
    "\n",
    "2. посчитайте, чему равна минимальная ставка;\n",
    "\n",
    "3. посчитайте, сколько раз была сделана минимальная ставка, и запишите результат в переменную min_bet_amount в виде целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls', header = None) #применяем header = None, потому что без этого воспримет первую строку\n",
    "# как заголовок\n",
    "\n",
    "log.columns = ['user','time','bet','win']\n",
    "log = log.fillna(0)\n",
    "\n",
    "bet = log[log['bet']>0]\n",
    "low = min(bet['bet'])\n",
    "bet = bet[bet['bet']==100]\n",
    "min_bet_amount = bet['bet'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Повторение Merge и Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv('users.xls', encoding='koi8_r', sep='\\t')\n",
    "users.columns = ['user','email','geo']\n",
    "\n",
    "log = pd.read_csv('log.xls', header = None) \n",
    "\n",
    "log.columns = ['user','time','bet','win']\n",
    "users\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим часть предобработки, которую мы должны были выполнить ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем признак user_id к одному формату в обоих датасетах  \n",
    "users.user = users.user.apply(lambda x: x.lower())  \n",
    "# Избавимся от ошибок в user_id  \n",
    "log = log[log.user != '#error']  \n",
    "log.user = log.user.str.split(' - ').apply(lambda x: x[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь объединим данные с помощью метода pd.merge():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(log, users, on = 'user')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный метод позволяет сгруппировать данные и применить к ним методы агрегации:\n",
    "\n",
    "df.groupby('user_id').win.median().median()  \n",
    "\n",
    "В данном случае мы группируем данные по признаку user_id.\n",
    "\n",
    "После этого мы в каждой группе выбираем признак win.\n",
    "\n",
    "Затем мы берем медиану каждой группы по признаку win и на выходе получаем таблицу, в которой индексом является признак user_id. В этой таблице единственный столбец - медиана по каждой группе (то есть по каждому пользователю).\n",
    "\n",
    "Наконец, последний вызов median() дает нам медиану по предыдущему столбцу, то есть возвращает одно число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('user').win.median().median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте медиану баланса по каждому пользователю. Для этого сгруппируйте по пользователям, возьмите признак net, просуммируйте по каждому пользователю и получите медиану."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Готовим датасет. Заменяем пропуски на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.xls', header = None) \n",
    "\n",
    "log.columns = ['user','time','bet','win']\n",
    "log['bet'] = log['bet'].fillna(0)\n",
    "log['win'] = log['win'].fillna(0)\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Пишем функцию, для различия выигрышей и проигрышей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_win(row):  \n",
    "    if row['win'] == row['bet']:\n",
    "        row['win'] = 0\n",
    "#         print(row['win']) \n",
    "        return row['win']\n",
    "    elif row['bet'] > row['win']:\n",
    "        row['win'] = -1\n",
    "#         print(row['win']) \n",
    "        return row['win']\n",
    "    else:\n",
    "        row['win'] = row['win']\n",
    "#         print(row['win']) \n",
    "        return row['win']\n",
    "        \n",
    "  \n",
    "# Применяем функцию  \n",
    "new_win = log.apply(lambda row: fillna_win(row), axis=1)  \n",
    "\n",
    "\n",
    "# Заменяем старый столбец с пропусками на новый без пропусков  \n",
    "log['win'] = new_win  \n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Пишем функцию для создание нового признака net (сумма выигрыша/проигрыша)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sence(row):\n",
    "    net = row['win']-row['bet']\n",
    "    print(net)\n",
    "    return net\n",
    "\n",
    "log['net'] = log.apply(lambda row: sence(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Загружаем датасет user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users.xls', encoding='koi8_r', sep='\\t')\n",
    "users.columns = ['user','email','geo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Сделаем предобработку датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем признак user_id к одному формату в обоих датасетах  \n",
    "users.user = users.user.apply(lambda x: x.lower())  \n",
    "# Избавимся от ошибок в user_id  \n",
    "log = log[log.user != '#error']  \n",
    "log.user = log.user.str.split(' - ').apply(lambda x: x[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Объединяем по пользователям оба датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd. merge(log,users, on = 'user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Группируем по пользователям признак net. Смотрим сумму по пользователям. И среднее потом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group = df.groupby('user').net.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
